---
weight: 1
sourceSHA: 688e8db6b4665c32b9fac29f9e0c2b4456e5c94e91421417cb52791ca43715e0
---

# Logs

## Log Query Analysis

In the operations center's log query analysis panel, you can view the standard output (stdout) logs of the logged-in account within its permissions, including system logs, product logs, Kubernetes logs, and application logs. Through these logs, you can gain insights into the operation of resources.

- **System Logs**: Logs from the host nodes, such as: dmesg, syslog/messages, secure, etc.
- **Product Logs**: Logs from the platform's own components and third-party components integrated with the platform, such as: Container-Platform, Platform-Center, DevOps, Service-Mesh, etc.
- **Kubernetes Logs**: Logs from Kubernetes container orchestration-related components, as well as logs generated by kubelet, kubeproxy, and docker, such as: docker, kube-apiserver, kube-controller-manager, etcd, etc.
- **Application Logs**: Logs from business applications, including file logs and standard output logs.

The log query conditions support filtering logs within a specified time range (either selected or custom), and display the query results through bar charts and standard output.

:::warning
For performance reasons, the platform can display a maximum of 10,000 logs at a time. If the log volume on the platform is too large over a period of time, please narrow the query's time range and query logs in stages.
:::

### Search Logs

1. In the left navigation bar, click **Operations Center** > **Logs** > **Log Query Analysis**.

2. Select the specified log type, query conditions, input the keywords of the log content you want to retrieve, and then click **Search**.

:::tip

- Different **Log Types** allow for different selectable query conditions.

- You can select or input multiple query condition tags; the query conditions for different resource types are in an AND relationship. Some query condition tags support multiple selections; please make sure to press the `Enter` key after making a choice to submit the options.

- Query conditions support fuzzy searches; for example, a query condition of `pod = nginx` can retrieve logs for `nginx-1`, `nginx-2`.

- Log content search conditions are only used to retrieve your log keywords and support the use of `AND` and `OR` parameters for associative queries. However, please note not to use `AND` and `OR` parameters simultaneously in a single query.

- The bar chart shows the total number of logs within the current query time range and the number of logs at different time points. Click on a bar in the chart to view the logs within the timeframe between that bar and the next one.

:::

### Export Log Data

The page can display a maximum of 10,000 log entries. When the number of logs retrieved is too large, you can use the log export feature to view up to 1 million log entries.

1. Click the **Export** button in the upper right corner of the bar chart, and configure the following parameters in the pop-up export log dialog.
   - **Scope**: The export range of logs, you can choose **Current Page** or **All Results**.
     - **Current Page**: Only export the query results on the current page, up to 1,000 entries.
     - **All Results**: Export all log data that meets the current query conditions, up to 1 million entries.

   - **Fields**: Display fields of the logs. You can select which field information to display in the exported log file by clicking the checkbox next to the field name.

     **Note**: Different log types have different selectable display fields, please select according to your actual needs.

   - **Format**: The export format of the log file, supporting `txt` or `csv`. The platform will export in `gzip` compressed format.

2. Click **Export**, and the browser will directly download the compressed file to your local machine.

### View Log Context

1. Double-click the log content area, and the current dialog will display 5 logs before and after the current log printing time, helping operation and maintenance personnel better understand the reasons for the current logs generated by resources.

2. You can set the display fields of the log context or export the log context. When exporting log context, there's no need to select the **Scope**; clicking the **Export** button will directly download the log context file to your local machine via the browser.

## Manage Application Log Retention Time

When no project policy is set, the retention time of application logs on the platform is determined by the `Application Log Retention Time` of the **Log Storage Plugin** installed on the **Storage Cluster** selected when **ACP Log Collector** was installed in the cluster where the application resides.

You can differentiate the retention time for **Application Logs** on the platform by adding and managing project log policies.

:::tip
Project policies only apply to **Application Logs** under a specific project. After setting a project policy, the retention time of all application logs under that project will follow the project policy.
:::

### Platform Administrator Sets Retention Policies

1. In the left navigation bar, click **Operations Center** > **Logs** > **Policy Management**.

2. Click **Add Project Policy**.

3. Click the dropdown box for **Project** and select a project.

4. Set the **Log Retention Time**.
   - Use the `-`/`+` buttons on both sides of the counter to decrease/increase the retention days, or directly enter a value in the counter. The platform allows setting the retention time range from 1 to 30 days.
   - If the input value is a decimal, it will be rounded up to an integer; if the input value is less than 1, it will round up to 1, and the `-` button will not be clickable; if the input value exceeds 30, it will round down to 30, and the `+` button will not be clickable.

5. Click **Add**.

### Project Administrator Sets Retention Policies

1. Go to the project detail page for the current project.

2. Click the edit button next to the log policy field to enable the log policy in the popup.

3. Set the **Log Retention Time**.

- Use the `-`/`+` buttons on both sides of the counter to decrease/increase the retention days, or directly enter a value in the counter. The platform allows setting the retention time range from 1 to 30 days.
- If the input value is a decimal, it will be rounded up to an integer; if the input value is less than 1, it will round up to 1, and the `-` button will not be clickable; if the input value exceeds 30, it will be rounded down to 30, and the `+` button will not be clickable.

### Set Retention Policies via CLI

1. Log into the `global` cluster and execute the following command:

   ```bash
   kubectl edit project <Project Name>
   ```

2. Modify the yaml as per the example below, save, and submit.

   ```yaml
   apiVersion: auth.alauda.io/v1
   kind: Project
   metadata:
     annotations:
       cpaas.io/creator: mschen1@alauda.io
       cpaas.io/description: ''
       cpaas.io/display-name: ''
       cpaas.io/operator: leizhuc
       cpaas.io/project.esPolicyLastEnabledTimestamp: '2025-02-18T09:53:54Z'
       cpaas.io/updated-at: '2025-02-18T09:53:54Z'
   creationTimestamp: '2025-02-13T08:19:11Z'
   finalizers:
     - namespace
   generation: 1
   labels:
     cpaas.io/project: bookinfo
     cpaas.io/project.esIndicesKeepDays: '7' # Retention duration of application logs under the project
     cpaas.io/project.esPolicyEnabled: 'true' # Enable project policy
     cpaas.io/project.id: '95447321'
     cpaas.io/project.level: '1'
     cpaas.io/project.parent: ''
   name: bookinfo
   ### More yaml information that is not involved in modification is omitted.
   ```

## Configure Partial Application Log Exclusion from Collection

If you only need to view **Real-Time Logs** of specific applications within the cluster without wishing to store those logs (the collector will discard the corresponding logs), you can refer to this section to set the scope for stopping log collection (cluster, namespace, Pod) for fine-grained control over application log collection.

### Stop Collecting All Application Logs in the Cluster

You can update the **Configuration Parameters** of the cluster's **ACP Log Collector** to turn off the **Application Log** collection switch, thereby uniformly updating the logging collection scope for that cluster. Once the collection switch for a certain type of log is turned off, it will stop collecting all logs of that type in the current cluster.

### Stop Collecting Application Logs in a Specific Namespace

You can turn off the log collection switch for that namespace by adding the label `cpaas.io/log.mute=true` to the specified namespace, thus stopping the collection of all standard output logs and file logs for all Pods in that namespace.

Optional configuration methods are as follows:

- **Command Line Method**: After logging into any control node of the cluster, execute the following command to update the namespace's label.

  ```bash
  kubectl label namespace <Namespace Name> cpaas.io/log.mute=true
  ```

- **Interface Operation Method**: In the **Project Management** view, update the namespace's label.
  1. In the project list of the **Project Management** view, click on the **_Project Name_** where the namespace is located.
  2. In the left navigation bar, click **Namespaces**.

  3. Click the **_Namespace Name_** whose label is to be updated.

  4. On the **Details** tab, click the operation button to the right of **Labels**.

  5. Add the label (Key: `cpaas.io/log.mute`, Value: `true`) or modify the value of an existing label, then click **Update**.

### Stop Collecting Pod Logs

You can turn off the log collection switch for the specified Pod by adding the label `cpaas.io/log.mute=true` to it, thus stopping the collection of standard output logs and file logs for that Pod.

After logging into any control node of the cluster, execute the following command to update the Pod's label.

```bash
kubectl label pod <Pod Name> -n <Namespace Name> cpaas.io/log.mute=true
```

**Note**: If the Pod belongs to a compute component (Workload), you can update the labels of the compute component (Deployment, StatefulSet, DaemonSet, Job, CronJob) to uniformly update the labels of all Pods under the compute component, and the labels will not be lost even after Pod recreation.

You can update the labels of the compute component in the following way.

1. In the **Container Platform** product view, click on the top navigation to switch to the namespace where the Pod is located.

2. In the left navigation bar, click **Compute Components** > **_Type of Compute Component to which the Pod Belongs_**.

3. Click the operation button to the right of the compute component to be updated > **Update**.

4. Click **YAML** in the upper right corner to switch to the YAML editing view.

5. Under the **spec.template.labels** field, add the `cpaas.io/log.mute: 'true'` label.

   An example is as follows:

   ```yaml
   spec:
     template:
       metadata:
         namespace: tuhao-test
         creationTimestamp: null
         labels:
           app: spilo
           cpaas.io/log.mute: 'true'
           cluster-name: acid-minimal-cluster
           role: exporter
           middleware.instance/name: acid-minimal-cluster
           middleware.instance/type: PostgreSQL
   ```

6. Click **Update**.
